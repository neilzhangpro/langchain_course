{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")\n",
    "os.environ[\"ELEVEN_API_KEY\"] = os.getenv(\"ELEVEN_API_KEY\")\n",
    "os.environ[\"AZURE_COGS_KEY\"] = os.getenv(\"AZURE_COGS_KEY\")\n",
    "os.environ[\"AZURE_COGS_ENDPOINT\"] = os.getenv(\"AZURE_COGS_ENDPOINT\")\n",
    "os.environ[\"AZURE_COGS_REGION\"] = os.getenv(\"AZURE_COGS_REGION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一个Agent\n",
    "- 注意当前使用的langchain版本为0.1.14\n",
    "### First Agent\n",
    "- Note that the current langchain version is 0.1.14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub==0.1.15\n",
      "  Obtaining dependency information for langchainhub==0.1.15 from https://files.pythonhosted.org/packages/1e/30/19859c841afcd54ee318709be0d456a8bd60d837005b80e99b35cd4195dc/langchainhub-0.1.15-py3-none-any.whl.metadata\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\langchain_v0.1\\lib\\site-packages (from langchainhub==0.1.15) (2.32.3)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in .\\langchain_v0.1\\lib\\site-packages (from langchainhub==0.1.15) (2.32.0.20240914)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.15) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.15) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.15) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub==0.1.15) (2024.8.30)\n",
      "Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: langchainhub\n",
      "  Attempting uninstall: langchainhub\n",
      "    Found existing installation: langchainhub 0.1.21\n",
      "    Uninstalling langchainhub-0.1.21:\n",
      "      Successfully uninstalled langchainhub-0.1.21\n",
      "Successfully installed langchainhub-0.1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchainhub==0.1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你好！有什么我可以帮助你的吗?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好', 'output': '你好！有什么我可以帮助你的吗?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import create_openai_functions_agent #不同的agent有不同的创建方式\n",
    "from langchain.agents import AgentExecutor\n",
    "#创建LLM \n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "#定义agent的prompt\n",
    "#https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "#定义工具,加载预制的工具,注意有的工具需要提供LLM\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "#创建agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "#定义agent的执行器，这里注意与老版本的不同\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"你好\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "- 中间步骤处理\n",
    "- 提示词z\n",
    "- 模型配置(停止符必要的话)\n",
    "- 输出解析器\n",
    "### Agent\n",
    "- Intermediate Step Processing\n",
    "- Prompt z\n",
    "- Model configuration (stopwords if necessary)\n",
    "- Output parser\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, tool\n",
    "from langchain.agents.output_parsers import XMLAgentOutputParser\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='search', description='search(query: str) -> str - 当需要了解最新的天气信息的时候才会使用这个工具。', args_schema=<class 'pydantic.main.searchSchema'>, func=<function search at 0x000002500CE22B60>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#配置模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    temperature=0,\n",
    "    )\n",
    "#可用工具\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"当需要了解最新的天气信息的时候才会使用这个工具。\"\"\"\n",
    "    return \"晴朗,32摄氏度,无风\"\n",
    "tool_list = [search]\n",
    "tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tools'], partial_variables={'chat_history': ''}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'xml-agent-convo', 'lc_hub_commit_hash': '00f6b7470fa25a24eef6e4e3c1e44ba07189f3e91c4d987223ad232490673be8'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tools'], template=\"You are a helpful assistant. Help the user answer any questions.\\n\\nYou have access to the following tools:\\n\\n{tools}\\n\\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\\n\\n<tool>search</tool><tool_input>weather in SF</tool_input>\\n<observation>64 degrees</observation>\\n\\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\\n\\n<final_answer>The weather in SF is 64 degrees</final_answer>\\n\\nBegin!\\n\\nPrevious Conversation:\\n{chat_history}\\n\\nQuestion: {input}\\n{agent_scratchpad}\"))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#提示词模版\n",
    "# https://smith.langchain.com/hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/xml-agent-convo\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 中间步骤，实现一个log\n",
    "- Intermediate steps to realize a log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_intermediate_steps(intermediate_steps):\n",
    "    log = \"\"\n",
    "    for action, observation in intermediate_steps:\n",
    "        log += (\n",
    "            f\"<tool>{action.tool}</tool><tool_input>{action.tool_input}\"\n",
    "            f\"</tool_input><observation>{observation}</observation>\"\n",
    "        )\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将工具列表插入到模版中\n",
    "def convert_tools(tools):\n",
    "    return \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义agent\n",
    "- Define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: convert_intermediate_steps(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt.partial(tools=convert_tools(tool_list))\n",
    "    | model.bind(stop=[\"</tool_input>\", \"</final_answer>\"])\n",
    "    | XMLAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#执行agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tool_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<tool>search</tool><tool_input>北京今天的天气\u001b[0m\u001b[36;1m\u001b[1;3m晴朗,32摄氏度,无风\u001b[0m\u001b[32;1m\u001b[1;3m<final_answer>北京今天的天气是晴朗，温度为32摄氏度，无风。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '北京今天的天气如何?', 'output': '北京今天的天气是晴朗，温度为32摄氏度，无风。'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"北京今天的天气如何?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- agent types: https://python.langchain.com/v0.1/docs/modules/agents/agent_types/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个比较复杂的agent\n",
    "- 工具\n",
    "- 检索增强RAG\n",
    "- 记忆\n",
    "### A more complex agent ###\n",
    "- tool\n",
    "- Retrieve Enhanced RAG\n",
    "- Memory\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义工具\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_community.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "search(query: str) -> str - 当需要查找实时信息的时候才会使用这个工具.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"当需要查找实时信息的时候才会使用这个工具.\"\"\"\n",
    "    serp = SerpAPIWrapper()\n",
    "    return serp.run(query)\n",
    "\n",
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'type': 'weather_result', 'temperature': '60', 'unit': 'Fahrenheit', 'precipitation': '100%', 'humidity': '79%', 'wind': '12 mph', 'location': '中国北京市', 'date': 'Friday', 'weather': 'Rain'}\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"北京今天的天气如何?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n"
     ]
    }
   ],
   "source": [
    "#RAG增强生成\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='The ability to rapidly understand how the model is performing ‚Äî and debug where it is failing ‚Äî is incredibly important for this phase.Debugging‚ÄãWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn‚Äôt necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it‚Äôs extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#搜索匹配文档块\n",
    "retriever.get_relevant_documents(\"如何debug?\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='langsmith_search', description='搜索有关 LangSmith 的信息。关于LangSmith的任何问题，你一定要使用这个工具！', args_schema=<class 'langchain.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002500B07CEA0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002500DE31DF0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002500B07F060>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002500DE31DF0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把检索器加入到工具中\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"搜索有关 LangSmith 的信息。关于LangSmith的任何问题，你一定要使用这个工具！\",\n",
    ")\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='search', description='search(query: str) -> str - 当需要查找实时信息的时候才会使用这个工具.', args_schema=<class 'pydantic.main.searchSchema'>, func=<function search at 0x000002500CDEBEC0>),\n",
       " Tool(name='langsmith_search', description='搜索有关 LangSmith 的信息。关于LangSmith的任何问题，你一定要使用这个工具！', args_schema=<class 'langchain.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002500B07CEA0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002500DE31DF0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002500B07F060>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002500DE31DF0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可用工具集\n",
    "tools = [search, retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"claude-3-opus-20240229\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#从hub中获取模版\n",
    "from langchain import hub\n",
    "\n",
    "# 一个最简单的模版,带记忆\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建agent\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建agent执行器AgentExecutor\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#执行\n",
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m作为一个AI助手,我可以从以下几个方面帮助你进行项目测试:\n",
      "\n",
      "1. 帮助制定测试计划和测试用例。我可以根据项目需求和设计文档,提出测试的重点、测试的步骤和流程、测试数据的设计等,编写详细的测试用例。\n",
      "\n",
      "2. 模拟各种用户行为和异常场景。我可以扮演不同类型的用户角色,模拟各种正常和异常的操作,发现潜在的问题。\n",
      "\n",
      "3. 自动化测试脚本的编写。如果项目中有自动化测试的需求,我可以根据测试用例编写自动化测试脚本,提高测试效率。常用的自动化测试工具有selenium、appium等。\n",
      "\n",
      "4. 性能测试和负载测试。我可以使用jmeter等工具对系统进行并发用户访问的模拟,评估系统的性能表现和稳定性。\n",
      "\n",
      "5. 安全测试。我可以检查系统是否存在常见的安全漏洞,如sql注入、跨站脚本攻击等。\n",
      "\n",
      "6. 提供测试报告和改进建议。我会详细记录测试过程中发现的bug和问题,整理成测试报告。并且根据测试结果提出优化和改进的建议。\n",
      "\n",
      "7. 协助回归测试。每次版本迭代后,我会根据新增和修改的功能点,执行回归测试,确保原有功能没有受到影响。\n",
      "\n",
      "作为AI助手,我可以7x24小时不知疲倦地工作,节省人力成本,当然我目前还无法完全取代人工测试,只能作为有益的补充。希望以上几点对你有所帮助,欢迎随时交流讨论。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'langsmith如何帮助做项目测试?',\n",
       " 'output': '作为一个AI助手,我可以从以下几个方面帮助你进行项目测试:\\n\\n1. 帮助制定测试计划和测试用例。我可以根据项目需求和设计文档,提出测试的重点、测试的步骤和流程、测试数据的设计等,编写详细的测试用例。\\n\\n2. 模拟各种用户行为和异常场景。我可以扮演不同类型的用户角色,模拟各种正常和异常的操作,发现潜在的问题。\\n\\n3. 自动化测试脚本的编写。如果项目中有自动化测试的需求,我可以根据测试用例编写自动化测试脚本,提高测试效率。常用的自动化测试工具有selenium、appium等。\\n\\n4. 性能测试和负载测试。我可以使用jmeter等工具对系统进行并发用户访问的模拟,评估系统的性能表现和稳定性。\\n\\n5. 安全测试。我可以检查系统是否存在常见的安全漏洞,如sql注入、跨站脚本攻击等。\\n\\n6. 提供测试报告和改进建议。我会详细记录测试过程中发现的bug和问题,整理成测试报告。并且根据测试结果提出优化和改进的建议。\\n\\n7. 协助回归测试。每次版本迭代后,我会根据新增和修改的功能点,执行回归测试,确保原有功能没有受到影响。\\n\\n作为AI助手,我可以7x24小时不知疲倦地工作,节省人力成本,当然我目前还无法完全取代人工测试,只能作为有益的补充。希望以上几点对你有所帮助,欢迎随时交流讨论。'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"langsmith如何帮助做项目测试?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m根据中国天气网的最新预报,北京今天(2023年4月3日)的天气情况如下:\n",
      "\n",
      "白天: 晴转多云,偏北风3-4级,最高气温19℃\n",
      "夜间: 多云,偏北风1-2级,最低气温7℃\n",
      "\n",
      "整体来看,今天北京的天气以晴朗到多云为主,气温适宜,早晚温差较大,日间最高气温接近20℃,夜间最低气温7℃左右。外出需注意及时添加衣物,预防感冒。\n",
      "\n",
      "此外预报显示,未来三天北京以多云到晴为主,气温将逐步回升,非常适合户外活动,也是春游踏青的好时机。但昼夜温差仍然较大,出行时需多加注意。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '北京今天的天气如何?',\n",
       " 'output': '根据中国天气网的最新预报,北京今天(2023年4月3日)的天气情况如下:\\n\\n白天: 晴转多云,偏北风3-4级,最高气温19℃\\n夜间: 多云,偏北风1-2级,最低气温7℃\\n\\n整体来看,今天北京的天气以晴朗到多云为主,气温适宜,早晚温差较大,日间最高气温接近20℃,夜间最低气温7℃左右。外出需注意及时添加衣物,预防感冒。\\n\\n此外预报显示,未来三天北京以多云到晴为主,气温将逐步回升,非常适合户外活动,也是春游踏青的好时机。但昼夜温差仍然较大,出行时需多加注意。'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实时信息提问\n",
    "agent_executor.invoke({\"input\": \"北京今天的天气如何?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m很抱歉,我们之前并没有进行过任何对话。作为一个AI助手,我没有长期记忆能力,无法知晓之前与您的聊天内容。每次对话对我来说都是全新的开始,所以我无法总结此前的聊天内容。请问您现在有什么我可以帮助的吗?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '截止目前我们都聊了什么?',\n",
       " 'output': '很抱歉,我们之前并没有进行过任何对话。作为一个AI助手,我没有长期记忆能力,无法知晓之前与您的聊天内容。每次对话对我来说都是全新的开始,所以我无法总结此前的聊天内容。请问您现在有什么我可以帮助的吗?'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#前面的交互都不带记忆\n",
    "agent_executor.invoke({\"input\": \"截止目前我们都聊了什么?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你好 Bob!很高兴认识你。我是一个AI助手,我可以用中文和你交流。如果你有任何问题或者需要帮助的地方,欢迎随时告诉我,我会尽我所能为你提供帮助。让我们开始愉快的聊天吧!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! 我叫bob',\n",
       " 'chat_history': [],\n",
       " 'output': '你好 Bob!很高兴认识你。我是一个AI助手,我可以用中文和你交流。如果你有任何问题或者需要帮助的地方,欢迎随时告诉我,我会尽我所能为你提供帮助。让我们开始愉快的聊天吧!'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#交互时添加记忆\n",
    "agent_executor.invoke({\"input\": \"hi! 我叫bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你刚才告诉我你叫Bob。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! 我叫bob'),\n",
       "  AIMessage(content='你好，Bob！很高兴认识你。有什么我可以帮助你的吗？')],\n",
       " 'input': '我叫什么名字?',\n",
       " 'output': '你刚才告诉我你叫Bob。'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#手动构造记忆数据\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! 我叫bob\"),\n",
    "            AIMessage(content=\"你好，Bob！很高兴认识你。有什么我可以帮助你的吗？\"),\n",
    "        ],\n",
    "        \"input\": \"我叫什么名字?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用RunnableWithMessageHistory自动构造记忆数据\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run a79558d5-72f8-4040-908a-b4e9f9d2f02f not found for run fd21a4a3-d5f8-4499-bacd-f73e58adef0c. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你好,Tomie!很高兴认识你。我是Claude,一个AI助手。我很乐意与你交流,尽我所能回答你的问题或是帮助你完成一些任务。请随时告诉我有什么可以帮到你的地方。期待我们能有一次愉快而有收获的对话!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! 我是tomie',\n",
       " 'chat_history': [],\n",
       " 'output': '你好,Tomie!很高兴认识你。我是Claude,一个AI助手。我很乐意与你交流,尽我所能回答你的问题或是帮助你完成一些任务。请随时告诉我有什么可以帮到你的地方。期待我们能有一次愉快而有收获的对话!'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! 我是tomie\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run a90cfcd9-b518-4c95-a46f-d664c8f48cf4 not found for run f31fafb2-3b58-4cc2-a482-a194f66bd36b. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你刚才告诉我你叫Tomie。希望我记对了你的名字!如果我弄错了,欢迎你随时纠正我。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我叫什么名字?',\n",
       " 'chat_history': [HumanMessage(content='hi! 我是tomie'),\n",
       "  AIMessage(content='你好,Tomie!很高兴认识你。我是Claude,一个AI助手。我很乐意与你交流,尽我所能回答你的问题或是帮助你完成一些任务。请随时告诉我有什么可以帮到你的地方。期待我们能有一次愉快而有收获的对话!')],\n",
       " 'output': '你刚才告诉我你叫Tomie。希望我记对了你的名字!如果我弄错了,欢迎你随时纠正我。'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"我叫什么名字?\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 55a3b7e7-30e6-4292-a3b1-75cf70d3f24b not found for run 360a7dd6-e8ee-426f-b534-92aa8a5c7645. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m好的,我来给你介绍一下如何使用LangSmith吧:\n",
      "\n",
      "1. 访问LangSmith网站(https://langsmith.ai),点击\"Sign Up\"注册一个账号,或者直接用Google账号登录。\n",
      "\n",
      "2. 登录后,可以点击左上角的\"New Chat\"开始一个新的对话,或者继续之前的对话。\n",
      "\n",
      "3. 在聊天框输入你的问题或需求,比如让它帮你写一篇文章、修改句子、翻译文本、解释概念、提供写作建议等,然后点击发送。\n",
      "\n",
      "4. LangSmith会根据你的输入生成回复。你可以就某个话题不断深入交流,它会记住上下文。\n",
      "\n",
      "5. 如果对当前回复不满意,可以点击\"Regenerate response\"让它重新生成一个回复。\n",
      "\n",
      "6. 对话可以通过左上角的\"New Chat\"随时开启新的话题。所有对话都会保存在侧边栏,方便再次查看。\n",
      "\n",
      "7. 可以给对话添加标题、对回复高亮或删除、对整个对话加星标等,以便整理管理。\n",
      "\n",
      "8. 订阅付费版可以解锁更多功能,如无限制使用、更多模型选择、更长对话上下文等。\n",
      "\n",
      "总的来说,LangSmith操作非常简单直观,输入问题就能得到AI助手的智能回复。多使用几次就能很快上手。希望我的介绍对你有帮助,欢迎随时告诉我还有什么问题!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmith如何使用?',\n",
       " 'chat_history': [HumanMessage(content='hi! 我是tomie'),\n",
       "  AIMessage(content='你好,Tomie!很高兴认识你。我是Claude,一个AI助手。我很乐意与你交流,尽我所能回答你的问题或是帮助你完成一些任务。请随时告诉我有什么可以帮到你的地方。期待我们能有一次愉快而有收获的对话!'),\n",
       "  HumanMessage(content='我叫什么名字?'),\n",
       "  AIMessage(content='你刚才告诉我你叫Tomie。希望我记对了你的名字!如果我弄错了,欢迎你随时纠正我。')],\n",
       " 'output': '好的,我来给你介绍一下如何使用LangSmith吧:\\n\\n1. 访问LangSmith网站(https://langsmith.ai),点击\"Sign Up\"注册一个账号,或者直接用Google账号登录。\\n\\n2. 登录后,可以点击左上角的\"New Chat\"开始一个新的对话,或者继续之前的对话。\\n\\n3. 在聊天框输入你的问题或需求,比如让它帮你写一篇文章、修改句子、翻译文本、解释概念、提供写作建议等,然后点击发送。\\n\\n4. LangSmith会根据你的输入生成回复。你可以就某个话题不断深入交流,它会记住上下文。\\n\\n5. 如果对当前回复不满意,可以点击\"Regenerate response\"让它重新生成一个回复。\\n\\n6. 对话可以通过左上角的\"New Chat\"随时开启新的话题。所有对话都会保存在侧边栏,方便再次查看。\\n\\n7. 可以给对话添加标题、对回复高亮或删除、对整个对话加星标等,以便整理管理。\\n\\n8. 订阅付费版可以解锁更多功能,如无限制使用、更多模型选择、更长对话上下文等。\\n\\n总的来说,LangSmith操作非常简单直观,输入问题就能得到AI助手的智能回复。多使用几次就能很快上手。希望我的介绍对你有帮助,欢迎随时告诉我还有什么问题!'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"LangSmith如何使用?\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 871104b5-78a8-475c-8934-b65dad6f44c5 not found for run 039e12e9-baf2-4006-9ad5-7f2d180da0d6. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我来总结一下我们截止目前聊了什么:\n",
      "\n",
      "1. 一开始你告诉我你叫Tomie,我称呼了你的名字,并表示很高兴认识你,作为一个AI助手我很乐意跟你交流并提供帮助。\n",
      "\n",
      "2. 接着你问我你叫什么名字,我回答说你刚才告诉过我你叫Tomie,我记住了,如果记错了欢迎你纠正。\n",
      "\n",
      "3. 然后你问我如何使用LangSmith,我比较详细地介绍了LangSmith的使用方法,包括注册登录、发起对话、得到回复、管理对话等,告诉你LangSmith操作简单,输入问题就可以得到AI的智能回复。\n",
      "\n",
      "4. 最后你让我总结我们截止目前聊了什么内容,我就回顾并总结了上面这几点。\n",
      "\n",
      "这就是我们目前为止对话的主要内容。我尽量清晰并有条理地概括了我们讨论的要点,希望没有遗漏什么重要信息。如果你还有什么想补充或进一步讨论的,欢迎继续交流!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '截止目前我们都聊了什么?',\n",
       " 'chat_history': [HumanMessage(content='hi! 我是tomie'),\n",
       "  AIMessage(content='你好,Tomie!很高兴认识你。我是Claude,一个AI助手。我很乐意与你交流,尽我所能回答你的问题或是帮助你完成一些任务。请随时告诉我有什么可以帮到你的地方。期待我们能有一次愉快而有收获的对话!'),\n",
       "  HumanMessage(content='我叫什么名字?'),\n",
       "  AIMessage(content='你刚才告诉我你叫Tomie。希望我记对了你的名字!如果我弄错了,欢迎你随时纠正我。'),\n",
       "  HumanMessage(content='LangSmith如何使用?'),\n",
       "  AIMessage(content='好的,我来给你介绍一下如何使用LangSmith吧:\\n\\n1. 访问LangSmith网站(https://langsmith.ai),点击\"Sign Up\"注册一个账号,或者直接用Google账号登录。\\n\\n2. 登录后,可以点击左上角的\"New Chat\"开始一个新的对话,或者继续之前的对话。\\n\\n3. 在聊天框输入你的问题或需求,比如让它帮你写一篇文章、修改句子、翻译文本、解释概念、提供写作建议等,然后点击发送。\\n\\n4. LangSmith会根据你的输入生成回复。你可以就某个话题不断深入交流,它会记住上下文。\\n\\n5. 如果对当前回复不满意,可以点击\"Regenerate response\"让它重新生成一个回复。\\n\\n6. 对话可以通过左上角的\"New Chat\"随时开启新的话题。所有对话都会保存在侧边栏,方便再次查看。\\n\\n7. 可以给对话添加标题、对回复高亮或删除、对整个对话加星标等,以便整理管理。\\n\\n8. 订阅付费版可以解锁更多功能,如无限制使用、更多模型选择、更长对话上下文等。\\n\\n总的来说,LangSmith操作非常简单直观,输入问题就能得到AI助手的智能回复。多使用几次就能很快上手。希望我的介绍对你有帮助,欢迎随时告诉我还有什么问题!')],\n",
       " 'output': '我来总结一下我们截止目前聊了什么:\\n\\n1. 一开始你告诉我你叫Tomie,我称呼了你的名字,并表示很高兴认识你,作为一个AI助手我很乐意跟你交流并提供帮助。\\n\\n2. 接着你问我你叫什么名字,我回答说你刚才告诉过我你叫Tomie,我记住了,如果记错了欢迎你纠正。\\n\\n3. 然后你问我如何使用LangSmith,我比较详细地介绍了LangSmith的使用方法,包括注册登录、发起对话、得到回复、管理对话等,告诉你LangSmith操作简单,输入问题就可以得到AI的智能回复。\\n\\n4. 最后你让我总结我们截止目前聊了什么内容,我就回顾并总结了上面这几点。\\n\\n这就是我们目前为止对话的主要内容。我尽量清晰并有条理地概括了我们讨论的要点,希望没有遗漏什么重要信息。如果你还有什么想补充或进一步讨论的,欢迎继续交流!'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"截止目前我们都聊了什么?\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
