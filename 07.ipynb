{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lost in the middle: 长上下文精度问题\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用Hugging Face Inference API来访问在Huggingface托管的嵌入模型\n",
    "- Use the Hugging Face Inference API to access embedded models hosted in Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "inference_api_key = getpass.getpass(\"Enter your HF Inference API Key:\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected each embedding in the embeddings to be a list, got [{'error': \"Authorization header is invalid, use 'Bearer API_TOKEN'\"}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m      7\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceInferenceAPIEmbeddings(\n\u001b[0;32m      8\u001b[0m     api_key\u001b[38;5;241m=\u001b[39minference_api_key, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-l6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m text \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m篮球是一项伟大的运动。\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m带我飞往月球是我最喜欢的歌曲之一。\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m拉里.伯德是一位标志性的NBA球员。\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m ]\n\u001b[1;32m---> 24\u001b[0m retrieval \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[0;32m     25\u001b[0m     search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m关于我的喜好都知道什么?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#根据相关性返回文本块\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# retrieve documents based on relevance\u001b[39;00m\n",
      "File \u001b[1;32me:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:748\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    743\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    744\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    745\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    746\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    747\u001b[0m     ):\n\u001b[1;32m--> 748\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    754\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32me:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:325\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[0;32m    320\u001b[0m             embeddings\u001b[38;5;241m=\u001b[39membeddings_without_metadatas,\n\u001b[0;32m    321\u001b[0m             documents\u001b[38;5;241m=\u001b[39mtexts_without_metadatas,\n\u001b[0;32m    322\u001b[0m             ids\u001b[38;5;241m=\u001b[39mids_without_metadatas,\n\u001b[0;32m    323\u001b[0m         )\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "File \u001b[1;32me:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:295\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[1;34m(self, ids, embeddings, metadatas, documents)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert\u001b[39m(\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    278\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     documents: Optional[OneOrMany[Document]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m     ids, embeddings, metadatas, documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_upsert(\n\u001b[0;32m    300\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    301\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[0;32m    305\u001b[0m     )\n",
      "File \u001b[1;32me:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:349\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[1;34m(self, ids, embeddings, metadatas, documents, require_embeddings_or_documents)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_embedding_set\u001b[39m(\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    336\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m     Optional[List[Document]],\n\u001b[0;32m    346\u001b[0m ]:\n\u001b[0;32m    347\u001b[0m     ids \u001b[38;5;241m=\u001b[39m validate_ids(maybe_cast_one_to_many(ids))\n\u001b[0;32m    348\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 349\u001b[0m         \u001b[43mvalidate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_cast_one_to_many\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     )\n\u001b[0;32m    353\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    354\u001b[0m         validate_metadatas(maybe_cast_one_to_many(metadatas))\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     )\n\u001b[0;32m    358\u001b[0m     documents \u001b[38;5;241m=\u001b[39m maybe_cast_one_to_many(documents) \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\chromadb\\api\\types.py:361\u001b[0m, in \u001b[0;36mvalidate_embeddings\u001b[1;34m(embeddings)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected embeddings to be a list with at least one item, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m     )\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;28misinstance\u001b[39m(e, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m embeddings]):\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected each embedding in the embeddings to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     )\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m embeddings:\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m embedding]):\n",
      "\u001b[1;31mValueError\u001b[0m: Expected each embedding in the embeddings to be a list, got [{'error': \"Authorization header is invalid, use 'Bearer API_TOKEN'\"}]"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain,StuffDocumentsChain\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "#使用huggingface托管的开源LLM来做嵌入，MiniLM-L6-v2是一个较小的LLM \n",
    "# use a smaller LLM model for embeddings\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=inference_api_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    ")\n",
    "\n",
    "text = [\n",
    "    \"篮球是一项伟大的运动。\",\n",
    "    \"带我飞往月球是我最喜欢的歌曲之一。\",\n",
    "    \"凯尔特人队是我最喜欢的球队。\",\n",
    "    \"这是一篇关于波士顿凯尔特人的文件。\",\n",
    "    \"我非常喜欢去看电影。\",\n",
    "    \"波士顿凯尔特人队以20分的优势赢得了比赛。\",\n",
    "    \"这只是一段随机的文字。\",\n",
    "    \"《艾尔登之环》是过去15年最好的游戏之一。\",\n",
    "    \"L.科内特是凯尔特人队最好的球员之一。\",\n",
    "    \"拉里.伯德是一位标志性的NBA球员。\"\n",
    "]\n",
    "\n",
    "retrieval = Chroma.from_texts(text,embeddings).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "query = \"关于我的喜好都知道什么?\"\n",
    "\n",
    "#根据相关性返回文本块\n",
    "# retrieve documents based on relevance\n",
    "docs = retrieval.invoke(query)\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='我非常喜欢去看电影。'),\n",
       " Document(page_content='带我飞往月球是我最喜欢的歌曲之一。'),\n",
       " Document(page_content='拉里.伯德是一位标志性的NBA球员。'),\n",
       " Document(page_content='这是一篇关于波士顿凯尔特人的文件。'),\n",
       " Document(page_content='《艾尔登之环》是过去15年最好的游戏之一。'),\n",
       " Document(page_content='L.科内特是凯尔特人队最好的球员之一。'),\n",
       " Document(page_content='波士顿凯尔特人队以20分的优势赢得了比赛。'),\n",
       " Document(page_content='这只是一段随机的文字。'),\n",
       " Document(page_content='篮球是一项伟大的运动。'),\n",
       " Document(page_content='凯尔特人队是我最喜欢的球队。')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对检索结果进行重新排序，根据论文的方案\n",
    "# according to the paper, re-order the retrieved documents\n",
    "#问题相关性越低的内容块放在中间\n",
    "# the lower the relevance to the question, the more in the middle\n",
    "#问题相关性越高的内容块放在头尾\n",
    "# the higher the relevance to the question, the more in the beginning and end\n",
    "\n",
    "reordering = LongContextReorder()\n",
    "reo_docs = reordering.transform_documents(docs)\n",
    "\n",
    "#头尾共有4个高相关性内容块\n",
    "# there are 4 high-relevance documents in the beginning and end\n",
    "reo_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我最喜欢做的事情是看电影。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检测下这种方案的精度效果\n",
    "# check the accuracy of this approach\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "#设置llm\n",
    "# set up the LLM\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "\n",
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\"],template=\"{page_content}\"\n",
    ")\n",
    "\n",
    "stuff_prompt_override =\"\"\"Given this text extracts:\n",
    "----------------------------------------\n",
    "{context}\n",
    "----------------------------------------\n",
    "Please answer the following questions:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=stuff_prompt_override,\n",
    "    input_variables=[\"context\",\"query\"]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "WorkChain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=\"context\"\n",
    ")\n",
    "\n",
    "#调用\n",
    "# invoke\n",
    "WorkChain.run(\n",
    "    input_documents=reo_docs,\n",
    "    query=\"我最喜欢做什么事情？\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
