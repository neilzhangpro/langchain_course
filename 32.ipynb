{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")\n",
    "os.environ[\"ELEVEN_API_KEY\"] = os.getenv(\"ELEVEN_API_KEY\")\n",
    "os.environ[\"AZURE_COGS_KEY\"] = os.getenv(\"AZURE_COGS_KEY\")\n",
    "os.environ[\"AZURE_COGS_ENDPOINT\"] = os.getenv(\"AZURE_COGS_ENDPOINT\")\n",
    "os.environ[\"AZURE_COGS_REGION\"] = os.getenv(\"AZURE_COGS_REGION\")\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何使用通义千问\n",
    "### How to use Tongyi\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM资源获取：\n",
    "- 打开 https://help.aliyun.com/zh/dashscope/developer-reference/activate-dashscope-and-create-an-api-key?spm=a2c4g.2399481.0.0\n",
    "- 按说明操作\n",
    "- 获得API-KEY\n",
    "- 安装包\n",
    "- 按照教程可以接入langchain\n",
    "- 注意：由于模型调教和参数关系，部分Agent type 千问是不支持的！类似create_react_agent这种比较简单的支持度会比较好！\n",
    "- agent type见官网 https://python.langchain.com/docs/modules/agents/agent_types/\n",
    "\n",
    "### LLM Resource Acquisition:\n",
    "- Open https://help.aliyun.com/zh/dashscope/developer-reference/activate-dashscope-and-create-an-api-key?spm=a2c4g.2399481.0.0\n",
    "- Follow the instructions\n",
    "- Obtain API-KEY\n",
    "- Installation package\n",
    "- You can integrate langchain according to the tutorial\n",
    "- Note: Due to model tuning and parameter relationships, some Agent types such as Q&A are not supported! Simpler types like create_react_agent have better support!\n",
    "- Agent types can be found on the official website https://python.langchain.com/docs/modules/agents/agent_types/\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the package\n",
    "! pip install --upgrade --quiet  dashscope  -i https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Tongyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Justin Bieber was born on March 1, 1994. The Super Bowl that took place in the early part of 1994 (January 29, 1994) was Super Bowl XXVIII. In that game, the Dallas Cowboys defeated the Buffalo Bills with a score of 30-13. Therefore, the NFL team that won the Super Bowl in the year Justin Bieber was born is the Dallas Cowboys.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tongyi().invoke(\"What NFL team won the Super Bowl in the year Justin Bieber was born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用chain\n",
    "### Use the chain\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, let's break it down step by step:\\n\\n1. First, we need to determine the year Justin Bieber was born.\\n   - Justin Bieber was born on March 1, 1994.\\n\\n2. Now that we know the year, we need to find out which Super Bowl took place in 1994.\\n   - The Super Bowl played in January of each year is for the previous year's NFL season. So, Super Bowl XXVIII (28) was played on January 30, 1994.\\n\\n3. Finally, we need to identify the winner of Super Bowl XXVIII.\\n   - In Super Bowl XXVIII, the Dallas Cowboys defeated the Buffalo Bills with a score of 30-13.\\n\\nTherefore, the NFL team that won the Super Bowl in the year Justin Bieber was born (1994) was the Dallas Cowboys.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = Tongyi()\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Agent\n",
    "### Using Agents\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = Tongyi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "#prompt = hub.pull(\"hwchase17/react\")\n",
    "#create_json_chat_agent\n",
    "prompt = hub.pull(\"hwchase17/react-chat-json\")\n",
    "#create_structured_chat_agent\n",
    "#prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent,create_structured_chat_agent,create_json_chat_agent\n",
    "# Construct a agent\n",
    "#agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "#agent = create_react_agent(llm, tools, prompt)\n",
    "agent = create_json_chat_agent(llm, tools, prompt)\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True,handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"get_word_length\",\n",
      "    \"action_input\": \"LangChain\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m9\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"LangChain这个单词有9个字母。\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LangChain这个单词有几个字母?', 'output': 'LangChain这个单词有9个字母。'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"LangChain这个单词有几个字母?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
