{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")\n",
    "os.environ[\"ELEVEN_API_KEY\"] = os.getenv(\"ELEVEN_API_KEY\")\n",
    "os.environ[\"AZURE_COGS_KEY\"] = os.getenv(\"AZURE_COGS_KEY\")\n",
    "os.environ[\"AZURE_COGS_ENDPOINT\"] = os.getenv(\"AZURE_COGS_ENDPOINT\")\n",
    "os.environ[\"AZURE_COGS_REGION\"] = os.getenv(\"AZURE_COGS_REGION\")\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = os.getenv(\"ZHIPUAI_API_KEY\")\n",
    "zhipukey =  os.getenv(\"ZHIPUAI_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"MOONSHOT_API_KEY\"] = os.getenv(\"MoonShot_key\")\n",
    "MoonShot_key = os.getenv(\"MoonShot_key\")\n",
    "os.environ[\"BAICHUAN_API_KEY\"] = os.getenv(\"BAICHUAN_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph muli-agents\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Obtaining dependency information for langchain_experimental from https://files.pythonhosted.org/packages/4c/99/3860e3653b670558a5a8cd1c9a33cc4238d66e8e7587929f1aef1c50d6e4/langchain_experimental-0.3.0-py3-none-any.whl.metadata\n",
      "  Using cached langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in .\\langchain_v0.2\\lib\\site-packages (from langchain_experimental) (0.3.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in .\\langchain_v0.2\\lib\\site-packages (from langchain_experimental) (0.3.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.1.125)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in .\\langchain_v0.2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\langchain_v0.2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\langchain_v0.2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_experimental) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in .\\langchain_v0.2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_experimental) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\langchain_v0.2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in .\\langchain_v0.2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\langchain_v0.2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\langchain_v0.2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\langchain_v0.2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\langchain_v0.2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in .\\langchain_v0.2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.11.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\langchain_v0.2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in .\\langchain_v0.2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\langchain_v0.2\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in .\\langchain_v0.2\\lib\\site-packages (from langchain<0.4.0,>=0.3.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\langchain_v0.2\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\langchain_v0.2\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\langchain_v0.2\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in .\\langchain_v0.2\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain_experimental) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in .\\langchain_v0.2\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\langchain_v0.2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\langchain_v0.2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\langchain_v0.2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\langchain_v0.2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\langchain_v0.2\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.0)\n",
      "Requirement already satisfied: anyio in .\\langchain_v0.2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in .\\langchain_v0.2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.5)\n",
      "Requirement already satisfied: sniffio in .\\langchain_v0.2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\langchain_v0.2\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\langchain_v0.2\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Using cached langchain_experimental-0.3.0-py3-none-any.whl (206 kB)\n",
      "Installing collected packages: langchain_experimental\n",
      "Successfully installed langchain_experimental-0.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# This executes code locally, which can be unsafe\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "#定义了两个下级成员：搜索和代码助手\n",
    "members = [\"Researcher\", \"Coder\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "llm = ChatZhipuAI(\n",
    "    model=\"GLM-4-Plus\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.with_structured_output(routeResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x241728e3770>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "research_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "#添加进图结构\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "# 直接运行python实际上很危险，langchain里提供了几个代码运行沙箱的工具可以替代\n",
    "code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "#搜索成员和码农成员就绪\n",
    "# 更新工作流\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # 所有的成员必须要给主管反馈执行结果\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# 包工头在状态中填充 \"next \"字段\n",
    "# 路由到某个节点或结束路由\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# 添加图的执行入口节点\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Coder'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coder': {'messages': [HumanMessage(content='I have executed the \"Hello, World!\" program and printed the output to the terminal. Here is the result:\\n\\n```\\nHello, World!\\n```\\n\\nIf you need the actual code to run this in your own environment, it would typically look like this in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```\\n\\nYou can run this code in any Python environment to see the \"Hello, World!\" message printed to the terminal.', additional_kwargs={}, response_metadata={}, name='Coder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Code hello world and print it to the terminal\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='### Research Report on Pikas\\n\\n**Introduction:**\\nPikas, small herbivorous mammals belonging to the genus Ochotona, are primarily found in mountainous regions. They are known for their diurnal activity and preference for rocky habitats known as talus. This report synthesizes recent research findings on pikas, focusing on their distribution, climatic relationships, and resilience in the face of environmental changes.\\n\\n**Distribution and Climatic Relationships:**\\nA comprehensive study compiling 2,387 records of extant pika sites since 2005, 89 records of extirpated sites, and 774 records of sites with old signs, reveals the extensive distribution of American pikas (Ochotona princeps) across the Great Basin, United States (Source: [Taylor & Francis Online](https://www.tandfonline.com/doi/full/10.1080/15230430.2018.1436296)). The research indicates that while pikas are disappearing from some locations due to climate change, their distribution is not solely confined to the Great Basin, with variable rates of decline across different regions (Source: [USGS](https://www.usgs.gov/news/national-news-release/pikas-disappearing-parts-west-due-climate-change)).\\n\\n**Adaptation and Resilience:**\\nPikas have demonstrated remarkable adaptability to climatic challenges. Studies show that they can overcome thermal dispersal barriers and re-colonize long-extirpated sites, possibly by moving during cooler nights (Source: [USDA Forest Service](https://www.fs.usda.gov/research/treesearch/64976)). This adaptability is further highlighted by their ability to thrive in warm regions where talus interiors remain cool, and their use of behavioral strategies to cope with climate change (Source: [USDA Forest Service Research](https://research.fs.usda.gov/news/highlights/american-pika-icon-climate-vulnerability-model-resilience)).\\n\\n**Conservation Status and Future Outlook:**\\nThe current conservation status of pikas is a subject of ongoing research. Mechanistic climatic models have accurately predicted historical and current distributions but have not accounted for pika presence at certain outlier sites, indicating a need for more nuanced models (Source: [Oxford Academic](https://academic.oup.com/jmammal/article/101/6/1466/5917619)). The variability in pika occupancy and abundance underscores the importance of understanding their natural history and adaptive traits in the context of environmental change.\\n\\n**Conclusion:**\\nPikas are a critical species for studying environmental change due to their sensitivity to climatic conditions. While they face threats from climate change, their adaptability offers hope for their persistence. Continued research is essential to inform conservation strategies and understand the broader implications of climate change on mountain-dwelling species.\\n\\n**References:**\\n- USDA Forest Service. (2023). Pika habitat and thermal ecology. Retrieved from [USDA Forest Service](https://www.fs.usda.gov/research/treesearch/64976)\\n- Beever, E. A., et al. (2018). Distribution and climatic relationships of the American pika (Ochotona princeps) in the Great Basin, United States. Journal of Biogeography, 45(12), 2537-2551. Retrieved from [Taylor & Francis Online](https://www.tandfonline.com/doi/full/10.1080/15230430.2018.1436296)\\n- USDA Forest Service Research. (2023). American pika: An icon of climate vulnerability and model of resilience. Retrieved from [USDA Forest Service Research](https://research.fs.usda.gov/news/highlights/american-pika-icon-climate-vulnerability-model-resilience)\\n- Smith, A. T., & Nagy, J. A. (2015). Pikas in stressful environments. Journal of Mammalogy, 101(6), 1466-1483. Retrieved from [Oxford Academic](https://academic.oup.com/jmammal/article/101/6/1466/5917619)\\n- U.S. Geological Survey. (2023). Pikas disappearing from parts of the West due to climate change. Retrieved from [USGS](https://www.usgs.gov/news/national-news-release/pikas-disappearing-parts-west-due-climate-change)', additional_kwargs={}, response_metadata={}, name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Write a brief research report on pikas.\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_v0.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
