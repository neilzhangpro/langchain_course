{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在链上使用记忆\n",
    "### Use memory on the chain\n",
    "- LLMChain\n",
    "- ConversationChain\n",
    "- 自定义\n",
    "- Customization\n",
    "- 同一个链合并使用多个记忆\n",
    "- Combining the use of multiple memories in the same chain\n",
    "- 给一个多参数链增加记忆\n",
    "- Adding memories to a multi-parameter chain\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义模板\n",
    "#create a custom template\n",
    "template = \"\"\"你是一个可以和人类对话的机器人.\n",
    "{chat_history}\n",
    "人类:{human_input}\n",
    "机器人:\"\"\"\n",
    "\n",
    "prompt= PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"chat_history\", \"human_input\"],\n",
    ")\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个可以和人类对话的机器人.\n",
      "\n",
      "人类:我最新喜欢我的世界这个游戏，你还记得我叫什么吗？\n",
      "机器人:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'human_input': '我最新喜欢我的世界这个游戏，你还记得我叫什么吗？',\n",
       " 'chat_history': '',\n",
       " 'text': ' 当然，你被命名为人类，因为你是一个人类。你在我的世界游戏中表现得很出色。'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"我最新喜欢我的世界这个游戏，你还记得我叫什么吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import  SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 你好，我是一个可以和人类对话的机器人\n",
      "Human: 你好\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"你好，我是一个可以和人类对话的机器人\",\n",
    "            role=\"system\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\",\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt.format(human_input=\"你好\",chat_history=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 你好，我是一个可以和人类对话的机器人\n",
      "Human: 我叫tomie，我是一个AI应用程序猿\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好，Tomie！很高兴认识你。作为一个AI应用程序猿，你对编程和人工智能方面有什么感兴趣的吗？有什么问题想要讨论或者了解的吗？我会尽力帮助你。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(human_input=\"我叫tomie，我是一个AI应用程序猿\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[]\n",
      "Human: 帮我做个一日游攻略\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '帮我做个一日游攻略',\n",
       " 'history': [HumanMessage(content='帮我做个一日游攻略'),\n",
       "  AIMessage(content='当然！您要去哪里旅行呢？如果是在日本东京，您可以先去浅草寺参拜，然后去上野动物园看可爱的动物们。接着可以去秋叶原购买一些电子产品或者动漫商品。最后可以去东京塔俯瞰整个城市的美景。您觉得这个行程如何？')],\n",
       " 'response': '当然！您要去哪里旅行呢？如果是在日本东京，您可以先去浅草寺参拜，然后去上野动物园看可爱的动物们。接着可以去秋叶原购买一些电子产品或者动漫商品。最后可以去东京塔俯瞰整个城市的美景。您觉得这个行程如何？'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"帮我做个一日游攻略\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义一下，对其进行覆盖\n",
    "#customize the prompt\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "template = \"\"\"下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'.\n",
    "当前对话:\n",
    "{history}\n",
    "Human:{input}\n",
    "AI助手:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"history\", \"input\"],\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(\n",
    "        ai_prefix=\"AI助手\",\n",
    "        return_messages=True,\n",
    "    ),\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'.\n",
      "当前对话:\n",
      "[]\n",
      "Human:你知道我叫什么名字吗?\n",
      "AI助手:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你知道我叫什么名字吗?',\n",
       " 'history': [HumanMessage(content='你知道我叫什么名字吗?'),\n",
       "  AIMessage(content='人类老爷，我真的不知道。')],\n",
       " 'response': '人类老爷，我真的不知道。'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"你知道我叫什么名字吗?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同一个链合并使用多个memory\n",
    "- Combining multiple memories in the same chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    CombinedMemory\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "#使用CoversationSummaryMemory对对话进行总结\n",
    "#use ConversationSummaryMemory to summarize the conversation\n",
    "summay = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    input_key=\"input\"\n",
    ")\n",
    "#使用ConversationBufferMemory对对话进行缓存\n",
    "#use ConversationBufferMemory to cache the conversation\n",
    "cov_memory = ConversationBufferMemory(\n",
    "    memory_key=\"history_now\",\n",
    "    input_key=\"input\",\n",
    ")\n",
    "\n",
    "memory = CombinedMemory(\n",
    "    memories=[summay, cov_memory],\n",
    ")\n",
    "\n",
    "TEMPLATE = \"\"\"下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'.\n",
    "之前的对话摘要:\n",
    "{history}\n",
    "当前对话:\n",
    "{history_now}\n",
    "Human:{input}\n",
    "AI：\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=TEMPLATE,\n",
    "    input_variables=[\"history\", \"history_now\", \"input\"],\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'.\n",
      "之前的对话摘要:\n",
      "\n",
      "当前对话:\n",
      "\n",
      "Human:那ETH呢？\n",
      "AI：\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '那ETH呢？',\n",
       " 'history': '',\n",
       " 'history_now': '',\n",
       " 'response': 'ETH是以太坊的缩写，是一种基于区块链技术的加密数字货币，也是智能合约平台。以太坊是一个开放的区块链平台，让开发者可以构建和部署去中心化应用程序。它的目标是提供一个去中心化的世界计算机，使得开发者可以构建智能合约和去中心化应用程序，而无需依赖第三方机构。以太坊的原生代币就是ETH，是支持以太坊网络上各种交易和智能合约操作的数字货币。ETH在加密货币市场中有很高的知名度和流通性，被广泛应用在各种区块链项目中。'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"那ETH呢？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多参数链增加记忆\n",
    "- Multi-parameter chains increase memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 24, which is longer than the specified 20\n",
      "Created a chunk of size 45, which is longer than the specified 20\n",
      "Created a chunk of size 50, which is longer than the specified 20\n",
      "Created a chunk of size 232, which is longer than the specified 20\n",
      "Created a chunk of size 589, which is longer than the specified 20\n",
      "Created a chunk of size 610, which is longer than the specified 20\n",
      "Created a chunk of size 561, which is longer than the specified 20\n",
      "Created a chunk of size 563, which is longer than the specified 20\n",
      "Created a chunk of size 259, which is longer than the specified 20\n",
      "Created a chunk of size 87, which is longer than the specified 20\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "with open(\"asset/letter.txt\") as f:\n",
    "    text = f.read()\n",
    "#切分文本\n",
    "#split the text\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size = 20,\n",
    "        chunk_overlap = 5\n",
    "    )\n",
    "    texts = text_splitter.split_text(text)\n",
    "\n",
    "#使用openai的embedding\n",
    "#use openai embedding\n",
    "    embddings = OpenAIEmbeddings()\n",
    "    #使用chroma向量存储\n",
    "    #use chroma to store the vectors\n",
    "    docssearch = Chroma.from_texts(\n",
    "        texts,\n",
    "        embddings,\n",
    "    )\n",
    "    query = \"公司有什么新策略?\"\n",
    "    docs = docssearch.similarity_search(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'，参考一下相关文档以及历史对话信息，AI会据此组织最终回答内容.\n",
      "Marketing Initiatives and Campaigns\n",
      "Our marketing team has been actively working on developing new strategies to increase brand awareness and drive customer engagement. We would like to thank Sarah Thompson (phone: 415-555-1234) for her exceptional efforts in managing our social media platforms. Sarah has successfully increased our follower base by 20% in the past month alone. Moreover, please mark your calendars for the upcoming product launch event on July 15th. We encourage all team members to attend and support this exciting milestone for our company.\n",
      "\n",
      "Dear Team,\n",
      "\n",
      "Subject: Updates and Discussions on Various Topics\n",
      "\n",
      "I hope this email finds you well. In this document, I would like to provide you with some important updates and discuss various topics that require our attention. Please treat the information contained herein as highly confidential.\n",
      "[]\n",
      "Human:公司的营销策略是什么？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='Marketing Initiatives and Campaigns\\nOur marketing team has been actively working on developing new strategies to increase brand awareness and drive customer engagement. We would like to thank Sarah Thompson (phone: 415-555-1234) for her exceptional efforts in managing our social media platforms. Sarah has successfully increased our follower base by 20% in the past month alone. Moreover, please mark your calendars for the upcoming product launch event on July 15th. We encourage all team members to attend and support this exciting milestone for our company.'),\n",
       "  Document(page_content='Dear Team,'),\n",
       "  Document(page_content='Subject: Updates and Discussions on Various Topics'),\n",
       "  Document(page_content='I hope this email finds you well. In this document, I would like to provide you with some important updates and discuss various topics that require our attention. Please treat the information contained herein as highly confidential.')],\n",
       " 'human_input': '公司的营销策略是什么？',\n",
       " 'chat_history': [HumanMessage(content='公司的营销策略是什么？'),\n",
       "  AIMessage(content='公司的营销策略包括开发新的策略来增加品牌知名度和推动客户参与。我们的营销团队一直在积极努力，特别要感谢Sarah Thompson在管理我们的社交媒体平台方面所做出的杰出努力。Sarah在过去一个月里成功地将我们的关注者基础增加了20%。此外，请记住7月15日即将举行的产品发布活动。我们鼓励所有团队成员参加并支持我们公司的这一重要里程碑。')],\n",
       " 'output_text': '公司的营销策略包括开发新的策略来增加品牌知名度和推动客户参与。我们的营销团队一直在积极努力，特别要感谢Sarah Thompson在管理我们的社交媒体平台方面所做出的杰出努力。Sarah在过去一个月里成功地将我们的关注者基础增加了20%。此外，请记住7月15日即将举行的产品发布活动。我们鼓励所有团队成员参加并支持我们公司的这一重要里程碑。'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建问答对话链\n",
    "#build a qa chain\n",
    "from langchain.chains.question_answering import  load_qa_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "template = \"\"\"下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'，参考一下相关文档以及历史对话信息，AI会据此组织最终回答内容.\n",
    "{context}\n",
    "{chat_history}\n",
    "Human:{human_input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"chat_history\", \"human_input\"],\n",
    ")\n",
    "\n",
    "#使用ConversationBufferMemory对对话进行缓存 \n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"human_input\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "#加载对话链\n",
    "chain = load_qa_chain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "chain.invoke({\"input_documents\":docs,\"human_input\":\"公司的营销策略是什么？\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
