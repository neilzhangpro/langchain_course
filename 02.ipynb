{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你是一个算命大师,帮我起1个具有法国特色的女孩名字'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#字符模板\n",
    "# string template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name},帮我起1个具有{county}特色的{sex}名字\")\n",
    "prompt.format(name=\"算命大师\",county=\"法国\",sex=\"女孩\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPromptTemplate\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师. 你的名字叫陈大师.'),\n",
       " HumanMessage(content='你好陈大师,你感觉如何？'),\n",
       " AIMessage(content='你好！我状态非常好!'),\n",
       " HumanMessage(content='你叫什么名字呢?'),\n",
       " AIMessage(content='你好！我叫陈大师'),\n",
       " HumanMessage(content='你的爸爸是谁呢?')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对话模板具有结构，chatmodels\n",
    "# chat template with structure\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个起名大师. 你的名字叫{name}.\"),\n",
    "        (\"human\", \"你好{name},你感觉如何？\"),\n",
    "        (\"ai\", \"你好！我状态非常好!\"),\n",
    "        (\"human\", \"你叫什么名字呢?\"),\n",
    "        (\"ai\", \"你好！我叫{name}\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template.format_messages(name=\"陈大师\", user_input=\"你的爸爸是谁呢?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师', additional_kwargs={'大师姓名': '陈瞎子'}),\n",
       " HumanMessage(content='请问大师叫什么?'),\n",
       " AIMessage(content='我叫陈瞎子')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 直接创建消息\n",
    "# create messages directly\n",
    "sy = SystemMessage(\n",
    "  content=\"你是一个起名大师\",\n",
    "  additional_kwargs={\"大师姓名\": \"陈瞎子\"}\n",
    ")\n",
    "\n",
    "hu = HumanMessage(\n",
    "  content=\"请问大师叫什么?\"\n",
    ")\n",
    "ai = AIMessage(\n",
    "  content=\"我叫陈瞎子\"\n",
    ")\n",
    "[sy,hu,ai]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatMessagePromptTemplate \n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='愿原力与你同在！', role='天行者')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从模板创建消息\n",
    "# create messages from template\n",
    "from langchain_core.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"愿{subject}与你同在！\"\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(role=\"天行者\",template=prompt)\n",
    "chat_message_prompt.format(subject=\"原力\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义模板\n",
    "### Customized templates\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
      "函数名称: hello_world\n",
      "源代码:\n",
      "def hello_world(abc):\n",
      "    print(\"Hello, world!\")\n",
      "    return abc\n",
      "\n",
      "代码解释:\n",
      "\n",
      "函数名称: hello_world\n",
      "源代码: \n",
      "def hello_world(abc): #定义函数hello_world,有一个参数abc\n",
      "    print(\"Hello, world!\") #打印输出\"Hello, world!\"\n",
      "    return abc #返回参数abc\n",
      "\n",
      "中文解释: \n",
      "这是一个名为hello_world的函数，它有一个参数abc。函数的作用是打印输出\"Hello, world!\"并返回参数abc。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##函数大师：根据函数名称，查找函数代码，并给出中文的代码说明\n",
    "# Function Master: Given a function name, find the function code and provide a Chinese code explanation\n",
    "\n",
    "\n",
    "from langchain_core.prompts import StringPromptTemplate\n",
    "\n",
    "\n",
    "# 定义一个简单的函数作为示例效果\n",
    "# Define a simple function as an example\n",
    "def hello_world(abc):\n",
    "    print(\"Hello, world!\")\n",
    "    return abc\n",
    "\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
    "函数名称: {function_name}\n",
    "源代码:\n",
    "{source_code}\n",
    "代码解释:\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    #获得源代码\n",
    "    # Get the source code\n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "#自定义的模板class\n",
    "# Custom template class\n",
    "class CustmPrompt(StringPromptTemplate):\n",
    "\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获得源代码\n",
    "        # Get the source code\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "\n",
    "        # 生成提示词模板\n",
    "        # Generate the prompt template\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__, source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "a = CustmPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "print(pm)\n",
    "\n",
    "#和LLM连接起来\n",
    "# Connect to LLM\n",
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_PROXY\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "msg = llm.invoke(pm)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用jinji2与f-string来实现提示词模板格式化\n",
    "### Using jinji2 with f-string for prompt word template formatting\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n给我讲一个关于翠花的悲伤故事\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f-string是python内置的一种模板引擎\n",
    "# f-string is a built-in template engine in Python\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "fstring_template = \"\"\"\n",
    "给我讲一个关于{name}的{what}故事\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(fstring_template)\n",
    "\n",
    "prompt.format(name=\"翠花\", what=\"悲伤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jinja2\n",
      "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/31/80/3a54838c3fb461f6fec263ebf3a3a41771bd05190238de3486aae8540c36/jinja2-3.1.4-py3-none-any.whl.metadata\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/3f/14/c3554d512d5f9100a95e737502f4a2323a1959f6d0d01e0d0997b35f7b10/MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/133.3 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 30.7/133.3 kB 435.7 kB/s eta 0:00:01\n",
      "   -------------------- ------------------ 71.7/133.3 kB 653.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 133.3/133.3 kB 872.6 kB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Installing collected packages: MarkupSafe, jinja2\n",
      "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'给我讲一个关于狗剩的高兴故事'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Jinja2是一个灵活、高效的Python模板引擎，可以方便地生成各种标记格式的文档。\n",
    "# Jinja2 is a flexible and efficient Python template engine that can easily generate documents in various markup formats.\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "jinja2_template = \"给我讲一个关于{{name}}的{{what}}故事\"\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "prompt.format(name=\"狗剩\", what=\"高兴\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合式提示词模板\n",
    "### Combined Cue Word Templates\n",
    "\n",
    "- Final prompt: 最终返回的提示词模板\n",
    "- Final prompt: Templates for the final returned cue word\n",
    "- Pipeline prompts：组成提示词管道的模板\n",
    "- Pipeline prompts：The templates that make up the cue word pipeline\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入模板\n",
    "# Import template\n",
    "from langchain_core.prompts import PipelinePromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 三层提示词设计\n",
    "- Three layers of cue word design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Prompt由一系列变量构成\n",
    "# Final Prompt consists of a series of variables\n",
    "full_template = \"\"\"{Character}\n",
    "{behavior}\n",
    "{prohibit}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第一层基本性格设计\n",
    "- Tier 1 Basic Personality Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Character_template = \"\"\"你是{person}，你有着{xingge}.\"\"\"\n",
    "Character_prompt = PromptTemplate.from_template(Character_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第二层行为设计\n",
    "- Tier 2 Behavioral Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_template = \"\"\"你遵从以下的行为:\n",
    "{behavior_list}\n",
    "\"\"\"\n",
    "behavior_prompt = PromptTemplate.from_template(behavior_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第三层不允许的行为\n",
    "- Tier 3 Disallowed Behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_template = \"\"\"你不允许有以下行为:\n",
    "{prohibit_list}\n",
    "\"\"\"\n",
    "prohibit_prompt = PromptTemplate.from_template(prohibit_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将三层提示词组合起来\n",
    "- Combine the three layers of cue words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = [\n",
    "    (\"Character\", Character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"prohibit\", prohibit_prompt)\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 打印下组合后模板里的可传递参数\n",
    "- Print the passable parameters in the combined template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xingge', 'prohibit_list', 'person', 'behavior_list']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 调用组合后的提示词模板\n",
    "- Call the combined prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是埃隆马斯克，你有着钢铁般的意志，你是世界首富，精通物理、天文、商业，你是商业奇才，你的终极梦想是殖民火星..\n",
      "你遵从以下的行为:\n",
      "1.你喜欢冒险 \n",
      " 2.你非常崇拜爱因斯坦 \n",
      " 3.你总是乐于助人，回答用户各种问题.\n",
      "\n",
      "你不允许有以下行为:\n",
      "1.你不可以说自己是一个人工智能助手或者机器人 \n",
      " 2.当你不知道答案的时候，可以说让我再想想. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pm = pipeline_prompt.format(\n",
    "    person=\"埃隆马斯克\",\n",
    "    xingge=\"钢铁般的意志，你是世界首富，精通物理、天文、商业，你是商业奇才，你的终极梦想是殖民火星.\",\n",
    "    behavior_list=\"1.你喜欢冒险 \\n 2.你非常崇拜爱因斯坦 \\n 3.你总是乐于助人，回答用户各种问题.\",\n",
    "    prohibit_list=\"1.你不可以说自己是一个人工智能助手或者机器人 \\n 2.当你不知道答案的时候，可以说让我再想想. \"\n",
    ")\n",
    "print(pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序列化：使用文件来管理提示词模板\n",
    "### Serialization: using files to manage cue word templates\n",
    "\n",
    "- 便于共享\n",
    "- Easy to share\n",
    "- 便于版本管理\n",
    "- Convenient for versioning\n",
    "- 便于存储\n",
    "- Convenient for storage\n",
    "- 支持常见格式(json/yaml/txt)\n",
    "- Support common formats (json/yaml/txt)\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给我讲一个关于小黑的恐怖的故事\n"
     ]
    }
   ],
   "source": [
    "prompt = load_prompt(\"asset/simple_prompt.yaml\")\n",
    "print(prompt.format(name=\"小黑\",what=\"恐怖的\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test小红test搞笑的test\n"
     ]
    }
   ],
   "source": [
    "#加载json格式的prompt模版\n",
    "# Load the prompt template in json format\n",
    "prompt = load_prompt(\"asset/simple_prompt.json\")\n",
    "print(prompt.format(name=\"小红\",what=\"搞笑的\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从0.1版本开始，出于安全考虑不再支持使用正则表达式来解析输出\n",
    "# Starting from version 0.1, regular expressions are no longer supported for parsing output for security reasons\n",
    "#prompt = load_prompt(\"asset/prompt_with_output_parser.json\")\n",
    "#prompt.output_parser.parse(\n",
    "#    \"George Washington was born in 1732 and died in 1799.\\nScore: 1/2\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 官方推荐使用langhub服务来远程加载提示词\n",
    "###  The official recommendation is to use the langhub service to remotely load cue words\n",
    "- hub是langSmith中的一部分\n",
    "- hub is part of langSmith.\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Obtaining dependency information for langchainhub from https://files.pythonhosted.org/packages/35/63/40328157ddee807991f2f1992c2ad88f479b2472dc9e40d08ccf10700735/langchainhub-0.1.21-py3-none-any.whl.metadata\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\langchain_v0.1\\lib\\site-packages (from langchainhub) (23.2)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\langchain_v0.1\\lib\\site-packages (from langchainhub) (2.32.3)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/8f/55/ea44dad71b9d92f86198f7448f5ba46ac919355f4f69bb1c0fa1af02b1b4/types_requests-2.32.0.20240914-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchainhub) (2024.8.30)\n",
      "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.21 types-requests-2.32.0.20240914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "[]\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [[]]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 今天天气如何？\n",
      "Thought:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "# 实际地址为 https://smith.langchain.com/hub/hwchase17/react\n",
    "# The actual address is https://smith.langchain.com/hub/hwchase17/react\n",
    "print(prompt.format(input=\"今天天气如何？\",tools=[],tool_names=[],agent_scratchpad=\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
