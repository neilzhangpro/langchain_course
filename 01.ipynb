{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境测试\n",
    "### Environmental test\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Obtaining dependency information for python-dotenv from https://files.pythonhosted.org/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#install package\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装OpenAI的官方SDK\n",
    "### Install the official SDK for OpenAI\n",
    "- 注意：OpenAi官方SDK也经历了多个大版本的迭代，一些API在后续的SDK中已经被丢弃，本课程主要以1.x大版本为主要依赖，在后续演示中可能会有依赖升级!\n",
    "- Note: The official OpenAi SDK has also gone through several major version iterations, and some APIs have been dropped in subsequent SDKs. This course focuses on major versions 1.x as the main dependencies, and dependency upgrades may be available in subsequent demos!\n",
    "*****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping openai as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.14.1\n",
      "  Obtaining dependency information for openai==1.14.1 from https://files.pythonhosted.org/packages/b3/05/4e1b778f3e261076354148e7716d14b95a279381e0a246e1fa7a5f574732/openai-1.14.1-py3-none-any.whl.metadata\n",
      "  Using cached openai-1.14.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai==1.14.1)\n",
      "  Obtaining dependency information for anyio<5,>=3.5.0 from https://files.pythonhosted.org/packages/3b/68/f9e9bf6324c46e6b8396610aef90ad423ec3e18c9079547ceafea3dce0ec/anyio-4.5.0-py3-none-any.whl.metadata\n",
      "  Using cached anyio-4.5.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai==1.14.1)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai==1.14.1)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/56/95/9377bcb415797e44274b51d46e3249eba641711cf3348050f76ee7b15ffc/httpx-0.27.2-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai==1.14.1)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting sniffio (from openai==1.14.1)\n",
      "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai==1.14.1)\n",
      "  Obtaining dependency information for tqdm>4 from https://files.pythonhosted.org/packages/48/5d/acf5905c36149bbaec41ccf7f2b68814647347b72075ac0b1fe3022fdc73/tqdm-4.66.5-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai==1.14.1)\n",
      "  Obtaining dependency information for typing-extensions<5,>=4.7 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai==1.14.1)\n",
      "  Obtaining dependency information for idna>=2.8 from https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl.metadata\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai==1.14.1)\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/12/90/3c9ff0512038035f59d279fddeb79f5f1eccd8859f06d6163c58798b9487/certifi-2024.8.30-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.14.1)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.14.1)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai==1.14.1)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai==1.14.1)\n",
      "  Obtaining dependency information for pydantic-core==2.23.4 from https://files.pythonhosted.org/packages/88/8d/479293e4d39ab409747926eec4329de5b7129beaedc3786eca070605d07f/pydantic_core-2.23.4-cp312-none-win_amd64.whl.metadata\n",
      "  Using cached pydantic_core-2.23.4-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in .\\langchain_v0.1\\lib\\site-packages (from tqdm>4->openai==1.14.1) (0.4.6)\n",
      "Using cached openai-1.14.1-py3-none-any.whl (257 kB)\n",
      "Using cached anyio-4.5.0-py3-none-any.whl (89 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp312-none-win_amd64.whl (1.9 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.5.0 certifi-2024.8.30 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 idna-3.10 openai-1.14.1 pydantic-2.9.2 pydantic-core-2.23.4 sniffio-1.3.1 tqdm-4.66.5 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#uninstall openai sdk\n",
    "! pip uninstall openai -y\n",
    "#install openai 0.28.0\n",
    "! pip install openai==1.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.14.1\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: E:\\教程\\imooc\\langchan_course\\langchain_v0.1\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "#show openai version\n",
    "! pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am an AI digital assistant here to help you with any questions or tasks you may have. I am programmed to provide accurate and helpful information to assist you in various ways. Feel free to ask me anything you need help with.\n"
     ]
    }
   ],
   "source": [
    "#注意这里与视频演示不一样，因为使用了1.x版本的openai sdk\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"intrdouce yourself\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装langchain依赖包\n",
    "### Installing langchain dependency packages\n",
    "- 注意：本课程以0.1.x大版本为主要依赖，由于langchain大版本的API变化较大，注意版本升级\n",
    "- Note: This course relies heavily on the 0.x and 1.x major releases, due to the large API changes in the langchain major releases, pay attention to version upgrades!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: langchain 0.3.0\n",
      "Uninstalling langchain-0.3.0:\n",
      "  Successfully uninstalled langchain-0.3.0\n",
      "Collecting langchain==0.1.14\n",
      "  Obtaining dependency information for langchain==0.1.14 from https://files.pythonhosted.org/packages/d5/d0/5e0bbcabe42f9e09c66fa0964b2ecdfee9a92cb2d7f05dd340b93203a40a/langchain-0.1.14-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.30 (from langchain==0.1.14)\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.30 from https://files.pythonhosted.org/packages/1b/d3/1f4d1941ae5a627299c8ea052847b99ad6674b97b699d8a08fc4faf25d3e/langchain_community-0.0.38-py3-none-any.whl.metadata\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.37 (from langchain==0.1.14)\n",
      "  Obtaining dependency information for langchain-core<0.2.0,>=0.1.37 from https://files.pythonhosted.org/packages/43/8b/48b7e6de9041d2b33d5108e154b82d1bd6c47cc68f0e44cb4fcdaccf5ec7/langchain_core-0.1.52-py3-none-any.whl.metadata\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.14)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.1,>=0.0.1 from https://files.pythonhosted.org/packages/68/6a/804fe5ca07129046a4cedc0697222ddde6156cd874c4c4ba29e4d271828a/langchain_text_splitters-0.0.2-py3-none-any.whl.metadata\n",
      "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (0.1.125)\n",
      "Requirement already satisfied: numpy<2,>=1 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in .\\langchain_v0.1\\lib\\site-packages (from langchain==0.1.14) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in .\\langchain_v0.1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\langchain_v0.1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\langchain_v0.1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\langchain_v0.1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\langchain_v0.1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in .\\langchain_v0.1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.11.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\langchain_v0.1\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in .\\langchain_v0.1\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\langchain_v0.1\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.14) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in .\\langchain_v0.1\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain==0.1.14) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\langchain_v0.1\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\langchain_v0.1\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\langchain_v0.1\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in .\\langchain_v0.1\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in .\\langchain_v0.1\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\langchain_v0.1\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\langchain_v0.1\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.14) (3.1.0)\n",
      "Requirement already satisfied: anyio in .\\langchain_v0.1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in .\\langchain_v0.1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.5)\n",
      "Requirement already satisfied: sniffio in .\\langchain_v0.1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\langchain_v0.1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\langchain_v0.1\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (1.0.0)\n",
      "Using cached langchain-0.1.14-py3-none-any.whl (812 kB)\n",
      "Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "Using cached langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "Using cached langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.2\n",
      "    Uninstalling langchain-core-0.3.2:\n",
      "      Successfully uninstalled langchain-core-0.3.2\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.0\n",
      "    Uninstalling langchain-text-splitters-0.3.0:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.0\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.0\n",
      "    Uninstalling langchain-community-0.3.0:\n",
      "      Successfully uninstalled langchain-community-0.3.0\n",
      "Successfully installed langchain-0.1.14 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-experimental 0.3.0 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.0.38 which is incompatible.\n",
      "langchain-experimental 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 0.1.52 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall langchain -y\n",
    "! pip install langchain==0.1.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一个langchain调用\n",
    "### The first langchain call\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='作为一个人工智能，我是由OpenAI创建和训练的一个模型，名为GPT-3。我被设计来理解和生成人类语言，帮助回答问题，写作，翻译等。虽然我可以生成人性化的文本，但请注意，我并没有情感、意识或个人经验。我的“知识”是基于我训练期间被提供的大量信息。', response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 15, 'total_tokens': 137, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bb9e1556-a64a-4e7b-840c-a6033472b024-0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hello world\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    )\n",
    "llm.invoke(\"介绍下你自己\")\n",
    "#notic:in the verion 1.x the predict api is deprecated,please use invoke api instead\n",
    "#llm.predict(\"介绍下你自己\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 起名大师\n",
    "### Name Master\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师,请模仿示例起3个中国特色的名字,比如男孩经常被叫做狗蛋,女孩经常被叫做翠花\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n男孩：小龙虎、小明月、小山水\\n女孩：小红梅、小桃李、小春风'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Name Master\n",
    "#Notice:in this example we use the gpt-3.5-turbo-instruct model,this not a chatmodel\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个{county}名字,比如男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message = prompt.format(county=\"中国特色的\",boy=\"狗蛋\",girl=\"翠花\")\n",
    "print(message)\n",
    "llm.invoke(message)\n",
    "#notic:in the verion 1.x the predict api is deprecated,please use invoke api instead\n",
    "#llm.predict(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 格式化输出\n",
    "### Formatted output\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "#自定义class，继承了BaseOutputParser\n",
    "# custom class that inherits from BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 起名大师格式化输出\n",
    "### Name Master Formatted output\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师,请模仿示例起3个具有美国男孩特色的名字,示例：男孩常用名sam,女孩常用名lucy。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\n",
      "\n",
      "\n",
      "jacob, michael, david\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jacob', ' michael', ' david']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#起名大师，输出格式为一个数组\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "#自定义类\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        print(text)\n",
    "        return text.strip().split(\",\")\n",
    "\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个具有{county}特色的名字,示例：男孩常用名{boy},女孩常用名{girl}。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\")\n",
    "message = prompt.format(county=\"美国男孩\",boy=\"sam\",girl=\"lucy\")\n",
    "print(message)\n",
    "strs = llm.invoke(message)\n",
    "CommaSeparatedListOutputParser().parse(strs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
