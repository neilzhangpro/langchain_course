{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent智能应用从0到1定制开发 \n",
    "## AI Agent Intelligent Application Custom Development from 0 to 1\n",
    "******\n",
    "- 此代码为网课《AI Agent智能应用从0到1定制开发》的配套代码，需要注意本套代码建议与网课适配配合食用。\n",
    "- This code for the online course <AI Agent Intelligent Applications from 0 to 1 custom development> supporting code, need to pay attention to this set of code is recommended with the online course adapted to work with consumption.\n",
    "- 需要注意由于课程开发周期的原因，langchain版本跨越了3个大版本，部分代码会与视频演示有差别!\n",
    "- Note that due to the course development cycle, the langchain version spans 3 major releases and some of the code will differ from the video demo!\n",
    "- 课程地址：https://coding.imooc.com/class/822.html\n",
    "- Course address: https://coding.imooc.com/class/822.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从环境变量中读取密钥\n",
    "### Read the key from the environment variable\n",
    "- 注意：尽量将你的OpenAI Key存储在类似.env文件中，而不是明文暴露在代码里，这是一种基本的安全措施\n",
    "- Note: Try to store your OpenAI Key in something like an .env file, rather than exposing it explicitly in code, as a basic safety measure!\n",
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"asset/openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_row',300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 几种不同的agent类型\n",
    "### Several different types of agent\n",
    "- ZERO_SHOT_REACT_DESCRIPTION\n",
    "- CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "- CONVERSATIONAL_REACT_DESCRIPTION\n",
    "- CHAT_CONVERSATIONAL_REACT_DESCRIPTION\n",
    "- OPENAI_FUNCTIONS\n",
    "- STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ZERO_SHOT_REACT_DESCRIPTION 零样本增强式生成，即在没有示例的情况下可以自主的进行对话的类型。https://blog.csdn.net/zcyzcyjava/article/details/127006287 [零样本、单样本、少样本]\n",
    "- Zero-shot generative dialogue, which can autonomously conduct conversations without examples. https://blog.csdn.net/zcyzcyjava/article/details/127006287 [Zero-shot, one-shot, few-shot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=True tags=['zero-shot-react-description'] agent=ZeroShotAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x00000187ECD1B770>, async_client=<openai.resources.completions.AsyncCompletions object at 0x00000187EEEC0A70>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')), output_parser=MRKLOutputParser(), allowed_tools=['Search', 'Calculator']) tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x00000187ECD1B770>, async_client=<openai.resources.completions.AsyncCompletions object at 0x00000187EEEC0A70>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x00000187ECD1B770>, async_client=<openai.resources.completions.AsyncCompletions object at 0x00000187EEEC0A70>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>)]\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    ")\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "print(agent)\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "#agent.invoke(\"现在美国总统是谁？他的年龄除以2是多少？\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CHAT_ZERO_SHOT_REACT_DESCRIPTION 使用了chatmodel\n",
    "- CHAT_ZERO_SHOT_REACT_DESCRIPTION uses chatmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=True tags=['chat-zero-shot-react-description'] agent=ChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \"action\" field are: Search, Calculator\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187ED148AD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187ECB57B00>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')), output_parser=ChatOutputParser(), allowed_tools=['Search', 'Calculator']) tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187ED148AD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187ECB57B00>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187ED148AD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187ECB57B00>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>)]\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: Search, Calculator\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "print(agent)\n",
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)\n",
    "#agent.invoke(\"现在美国总统是谁？他的年龄除以2是多少？\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CONVERSATIONAL_REACT_DESCRIPTION 一个对话型的agent，这个agent要求与memory一起使用\n",
    "- CONVERSATIONAL_REACT_DESCRIPTION A conversational agent, this agent requires to be used with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(memory_key='chat_history') verbose=True tags=['conversational-react-description'] agent=ConversationalAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\n> Calculator: Useful for when you need to answer questions about math.\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nAI: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x00000187ED147170>, async_client=<openai.resources.completions.AsyncCompletions object at 0x00000187EEEC3BC0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')), output_parser=ConvoOutputParser(), allowed_tools=['Search', 'Calculator'], ai_prefix='AI') tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x00000187ED147170>, async_client=<openai.resources.completions.AsyncCompletions object at 0x00000187EEEC3BC0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x00000187ED147170>, async_client=<openai.resources.completions.AsyncCompletions object at 0x00000187EEEC3BC0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>)] handle_parsing_errors=True\n",
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "> Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "#memory component\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    ")\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,#记忆组件\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(agent)\n",
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Hi, welcome to Assistant! How can I assist you today?\n",
      "\n",
      "Action: Search\n",
      "Action Input: Who is Tomie?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\"Tomie Kawakami, better known mononymously as Tomie, is a character from the Japanese horror manga and film series of the same name created by Junji Ito. Tomie made her first appearance in Ito's 1987 manga Tomie, which was published in Monthly Halloween, a shōjo magazine.\", 'Tomie Kawakami type: Film character.', 'Tomie Kawakami entity_type: fictional_universe, people.', 'Tomie Kawakami main_tab_text: Overview.', 'Tomie Kawakami kgmid: /g/11bvssns88.', 'Tomie Kawakami notable_aliases: Ayaka Nakamura, Mai Oyama, Marina, Miho Kaneshiro, Tomie, Tomie Iizuka, Tomie Kawakami.', 'Tomie Kawakami created_by: Junji Ito.', 'Tomie Kawakami first_appearance: Tomie (1987).', 'Tomie Kawakami last_appearance: Tomie - Takeover (2018).', 'Tomie Kawakami better known mononymously as Tomie, is a character from the Japanese horror manga and film series of the same name created by Junji Ito.', \"Tomie is a manipulative, hedonistic, and extremely selfish woman, seducing men to do her bidding. She is one of Junji Ito's most recurring characters, ...\", \"Tomie (Japanese: 富江) is a Japanese horror manga series written and illustrated by Junji Ito. Tomie was Ito's first published work he originally submitted to ...\", 'Tomie Kawakami (in Japanese: 富江) is the titular main antagonist of the Tomie franchise. Though Tomie appears human, she has an array of bizarre biological ...', 'Tomie is not a curse or a vengeful spirit. She is the definition of evil. There is no reasoning with her or trying to get on her good side. She ...', 'The story of Tomie begins with a high school student named Tomie Kawakami, who is murdered by her jealous classmates after they become obsessed with her beauty.', \"Tomie is one of Junji Ito's most notable characters. She is basically an eldritch abomination in the form of a beautiful human girl. She is ...\", 'Tomie is a horror story about a mysterious girl named Tomie who has the power to seduce and manipulate men, driving them to madness and extreme violence.', \"Tomie is one of Junji Ito's early works. It's about a girl that keeps dying over and over again, thanks to others inflicting violence on her.\", \"With countless classics under Junji Ito's belt, Tomie stands a cut above the rest. Link to the Discord: https://discord.gg/sPbsBzv Link to ...\"]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ` Tomie is a character from the Japanese horror manga series created by Junji Ito. She is known for her manipulative and hedonistic nature, and has the power to seduce and control men. Is there anything else you would like to know about Tomie?`\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: `I'm sorry, I couldn't find any information on \"Hi Tomie\". Could you please provide more context or details?`\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? Yes\n",
      "Action: Search\n",
      "Action Input: Would you like to know more about Tomie and the Tomie series?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mOriginally serialized in Weekly Manga Action from 1987 to 1999, “Tomie” is a sprawling anthology that follows the exploits of the eponymous character, a beautiful young woman whose mere presence incites uncontrollable obsession and violence in all who encounter her.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: I hope that provides some insight into the Tomie series. Is there anything else you would like to know?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi i am tomie',\n",
       " 'chat_history': '',\n",
       " 'output': 'I hope that provides some insight into the Tomie series. Is there anything else you would like to know?'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"hi i am tomie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Your name is Tomie.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is my name?',\n",
       " 'chat_history': 'Human: hi i am tomie\\nAI: I hope that provides some insight into the Tomie series. Is there anything else you would like to know?',\n",
       " 'output': 'Your name is Tomie.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAI: 嗯，泰国菜有很多种，每种都有不同的特色。如果你喜欢辣的，我可以推荐你品尝一下冬阴功汤或者咖喱鸡，它们都是非常受欢迎的菜肴。如果你喜欢甜辣口味，那么芒果鸡或者青木瓜沙拉可能会更合你的口味。如果你想尝试一些有趣的菜肴，可以尝试一下泰式炸春卷或者泰式凉拌粉丝。总的来说，泰国菜具有丰富多样的口味，你可以根据自己的喜好选择。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '有什么好吃的泰国菜可以推荐给我吗?',\n",
       " 'chat_history': 'Human: hi i am tomie\\nAI: I hope that provides some insight into the Tomie series. Is there anything else you would like to know?\\nHuman: what is my name?\\nAI: Your name is Tomie.',\n",
       " 'output': '嗯，泰国菜有很多种，每种都有不同的特色。如果你喜欢辣的，我可以推荐你品尝一下冬阴功汤或者咖喱鸡，它们都是非常受欢迎的菜肴。如果你喜欢甜辣口味，那么芒果鸡或者青木瓜沙拉可能会更合你的口味。如果你想尝试一些有趣的菜肴，可以尝试一下泰式炸春卷或者泰式凉拌粉丝。总的来说，泰国菜具有丰富多样的口味，你可以根据自己的喜好选择。'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"有什么好吃的泰国菜可以推荐给我吗?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "AI: 你的名字的最后一个字母是\"e\"。1998年的世界杯法国队夺冠了，他们在决赛中击败了巴西队。那是一个非常精彩的比赛，你可以看看相关的比赛录像来回味一下。 \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    agent.invoke(\"这些我都没吃过！我名字的最后一个字母是什么？1998年的世界杯谁夺冠了？\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Search\n",
      "Action Input: What is the current temperature in Xi'an, China?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '71', 'unit': 'Fahrenheit', 'precipitation': '0%', 'humidity': '68%', 'wind': '17 mph', 'location': \"Xi'An, Shaanxi, China\", 'date': 'Friday 2:00 PM', 'weather': 'Mostly cloudy'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? Yes\n",
      "Action: N/A\n",
      "AI: As for our conversation, we discussed your name, Thai cuisine recommendations, and the 1998 World Cup winner.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '中国陕西西安现在的气温多少？截止目前我们聊了什么？',\n",
       " 'chat_history': 'Human: hi i am tomie\\nAI: I hope that provides some insight into the Tomie series. Is there anything else you would like to know?\\nHuman: what is my name?\\nAI: Your name is Tomie.\\nHuman: 有什么好吃的泰国菜可以推荐给我吗?\\nAI: 嗯，泰国菜有很多种，每种都有不同的特色。如果你喜欢辣的，我可以推荐你品尝一下冬阴功汤或者咖喱鸡，它们都是非常受欢迎的菜肴。如果你喜欢甜辣口味，那么芒果鸡或者青木瓜沙拉可能会更合你的口味。如果你想尝试一些有趣的菜肴，可以尝试一下泰式炸春卷或者泰式凉拌粉丝。总的来说，泰国菜具有丰富多样的口味，你可以根据自己的喜好选择。\\nHuman: 这些我都没吃过！我名字的最后一个字母是什么？1998年的世界杯谁夺冠了？\\nAI: 你的名字的最后一个字母是\"e\"。1998年的世界杯法国队夺冠了，他们在决赛中击败了巴西队。那是一个非常精彩的比赛，你可以看看相关的比赛录像来回味一下。',\n",
       " 'output': 'As for our conversation, we discussed your name, Thai cuisine recommendations, and the 1998 World Cup winner.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"中国陕西西安现在的气温多少？截止目前我们聊了什么？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CHAT_CONVERSATIONAL_REACT_DESCRIPTION 使用了chatmodel\n",
    "- CHAT_CONVERSATIONAL_REACT_DESCRIPTION used chatmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['chat-conversational-react-description'] agent=ConversationalChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\n> Calculator: Useful for when you need to answer questions about math.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of Search, Calculator\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF40BB60>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EEEC5550>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')), output_parser=ConvoOutputParser(), allowed_tools=['Search', 'Calculator'], template_tool_response=\"TOOL RESPONSE: \\n---------------------\\n{observation}\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\") tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF40BB60>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EEEC5550>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF40BB60>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EEEC5550>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>)] handle_parsing_errors=True\n",
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "> Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of Search, Calculator\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "{input}\n",
      "variable_name='agent_scratchpad'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import  ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,#记忆组件\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(agent)\n",
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)\n",
    "print(agent.agent.llm_chain.prompt.messages[2].prompt.template)\n",
    "print(agent.agent.llm_chain.prompt.messages[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Hello Tony, how can I assist you today?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi i am tony',\n",
       " 'chat_history': [HumanMessage(content='hi i am tony'),\n",
       "  AIMessage(content='Hello Tony, how can I assist you today?')],\n",
       " 'output': 'Hello Tony, how can I assist you today?'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"hi i am tony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Your name is Tony.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is my name?',\n",
       " 'chat_history': [HumanMessage(content='hi i am tony'),\n",
       "  AIMessage(content='Hello Tony, how can I assist you today?'),\n",
       "  HumanMessage(content='what is my name?'),\n",
       "  AIMessage(content='Your name is Tony.')],\n",
       " 'output': 'Your name is Tony.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Search\",\n",
      "    \"action_input\": \"推荐泰国菜\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['要说到泰菜里面Vivian最喜欢的一定要属菠萝炒饭啦！泰国香米的香气，搭配菠萝独有的酸酸甜甜的味道，真的是升华了整道炒饭的口感！而且这道菜营养均衡，有主食， ...', '这10道泰国菜美味又健康，你吃过几道？ · 青木瓜沙拉(ส้มตำ) · 泰式柚子沙拉(ยำส้มโอ) · 泰式春卷(ปอเปี๊ยะสด) · 清汤冬阴功(ต้มยำกุ้งน้ำใส) · 海南鸡饭(ข้าวมันไก่) · 柠檬 ...', '10道必尝的泰国菜 · Larb Moo · Phad Thai · Khao Soi · Kra Pao Moo Krob · Som Tam · Gai Pad Med Ma Muang · Hor Mok Pla ...', '1.冬阴功汤-经典口味，泰式热辣 · 2.青木瓜沙拉-世界十大最佳沙拉 · 3.泰式炒河粉-家喻户晓的菜肴 · 4.泰式猪脚饭-老字号，米其林推荐 · 5.打抛猪肉饭-民间美食 ...', '泰式椰汁鸡汤 · 寿喜烧 · 泰式烤鸡 · 泰式炒裸条 · 打抛叶 · 冬荫功汤 · 泰式青木瓜沙拉 · 海南鸡饭.', '香辣酸甜最够味，洛杉矶12家泰国菜推荐泰式料理可不只有冬阴功汤 · 1. Thai Bamboo Bistro | 家常便饭好去处 · 2. Mint Leaf Thai Cuisine | 吃完喝完去 ...', '（一）\\u200b\\u200b 作为泰国菜的代表——冬荫功汤，想必是很多朋友最为熟悉的泰国菜！ CNN推荐名单中，冬荫功汤稳居第一，一直颇受外国游客欢迎，冬荫功也是许多来泰国 ...', '纽约市泰餐餐厅 · 1. Bua Thai Ramen & Robata Grill. (847) · 2. Pure Thai Cookhouse. (1,548) · 3. Thai Villa. (229) · 4. Obao Midtown. (423) · 5. Up Thai · 6. VIV Thai ...', '排名前十的泰国菜——普吉岛最受欢迎的大众美食推荐 · 01 冬阴功汤 · 02 泰式炒河粉 · 03 粿条（汤面） · 04 凉拌木瓜丝 · 05 腰果炒鸡肉 · 06 绿咖喱鸡 · 07 ...', '《米其林指南泰国2020》——10 道米其林评审员推荐泰国菜 · 1. 蟹黄佐鲭鱼（Crab Roe Relish with Mackerel） · 2. 鸡肉沙爹佐浓花生酱（Chicken Satay with ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"一些值得推荐的泰国菜包括菠萝炒饭，这是一种香米炒饭，加入了菠萝，使得口味酸甜，很受欢迎。你也可以尝试冬阴功汤，这是一种著名的泰国辣汤，以及青木瓜沙拉，这是一种世界著名的沙拉，其中包括了辣椒，大蒜，豆类等食材。泰式炒粿条和绿咖喱鸡也是非常流行的选择。这些建议都来源于人们对泰国菜的喜爱和推荐，希望你会喜欢这些经典的泰国风味。\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '有什么好吃的泰国菜给我推荐一下？',\n",
       " 'chat_history': [HumanMessage(content='hi i am tony'),\n",
       "  AIMessage(content='Hello Tony, how can I assist you today?'),\n",
       "  HumanMessage(content='what is my name?'),\n",
       "  AIMessage(content='Your name is Tony.'),\n",
       "  HumanMessage(content='有什么好吃的泰国菜给我推荐一下？'),\n",
       "  AIMessage(content='一些值得推荐的泰国菜包括菠萝炒饭，这是一种香米炒饭，加入了菠萝，使得口味酸甜，很受欢迎。你也可以尝试冬阴功汤，这是一种著名的泰国辣汤，以及青木瓜沙拉，这是一种世界著名的沙拉，其中包括了辣椒，大蒜，豆类等食材。泰式炒粿条和绿咖喱鸡也是非常流行的选择。这些建议都来源于人们对泰国菜的喜爱和推荐，希望你会喜欢这些经典的泰国风味。')],\n",
       " 'output': '一些值得推荐的泰国菜包括菠萝炒饭，这是一种香米炒饭，加入了菠萝，使得口味酸甜，很受欢迎。你也可以尝试冬阴功汤，这是一种著名的泰国辣汤，以及青木瓜沙拉，这是一种世界著名的沙拉，其中包括了辣椒，大蒜，豆类等食材。泰式炒粿条和绿咖喱鸡也是非常流行的选择。这些建议都来源于人们对泰国菜的喜爱和推荐，希望你会喜欢这些经典的泰国风味。'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"有什么好吃的泰国菜给我推荐一下？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Search\",\n",
      "    \"action_input\": \"1998年世界杯冠军球队\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFrance national football team\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"你名字的最后一个字母是Y。1998年的世界杯冠军是法国国家足球队。\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我都没吃过！我名字的最后一个字母是什么？1998年的世界杯谁夺冠了？',\n",
       " 'chat_history': [HumanMessage(content='hi i am tony'),\n",
       "  AIMessage(content='Hello Tony, how can I assist you today?'),\n",
       "  HumanMessage(content='what is my name?'),\n",
       "  AIMessage(content='Your name is Tony.'),\n",
       "  HumanMessage(content='有什么好吃的泰国菜给我推荐一下？'),\n",
       "  AIMessage(content='一些值得推荐的泰国菜包括菠萝炒饭，这是一种香米炒饭，加入了菠萝，使得口味酸甜，很受欢迎。你也可以尝试冬阴功汤，这是一种著名的泰国辣汤，以及青木瓜沙拉，这是一种世界著名的沙拉，其中包括了辣椒，大蒜，豆类等食材。泰式炒粿条和绿咖喱鸡也是非常流行的选择。这些建议都来源于人们对泰国菜的喜爱和推荐，希望你会喜欢这些经典的泰国风味。'),\n",
       "  HumanMessage(content='我都没吃过！我名字的最后一个字母是什么？1998年的世界杯谁夺冠了？'),\n",
       "  AIMessage(content='你名字的最后一个字母是Y。1998年的世界杯冠军是法国国家足球队。')],\n",
       " 'output': '你名字的最后一个字母是Y。1998年的世界杯冠军是法国国家足球队。'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"我都没吃过！我名字的最后一个字母是什么？1998年的世界杯谁夺冠了？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OPENAI_FUNCTIONS，使用openai的函数调用来实现的，只支持openai模型。\n",
    "- OPENAI_FUNCTIONS, implemented using openai's function calls, only supports openai models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['openai-functions'] agent=OpenAIFunctionsAgent(llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF406480>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EF4066C0>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1'), tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF406480>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EF4066C0>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF406480>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EF4066C0>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>)], prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessage(content='You are a helpful AI assistant.'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]), output_parser=<class 'langchain.agents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser'>) tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e8c972251bd371ef03c23b9bc9e1ad49cb8cb7823befbfda0c8980d7a66b5fa0', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF406480>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EF4066C0>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EF406480>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EF4066C0>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))>)] handle_parsing_errors=True\n",
      "[SystemMessage(content='You are a helpful AI assistant.'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import  ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    memory=memory,#记忆组件\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(agent)\n",
    "print(agent.agent.prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `\n",
      "Bitcoin price today`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m63,788.00\u001b[0mError code: 400 - {'error': {'message': \"Invalid value for 'content': expected a string, got null. (request id: 20240920141958695731667QDbRHg8U) (request id: 2024092006195854962508799305644)\", 'type': 'invalid_request_error', 'param': 'messages.[2].content', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    agent.invoke(\"今天比特币的价格是多少？它的价格开平方是多少？\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION 对输出做了结构化处理\n",
    "- STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION Structures the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['structured-chat-zero-shot-react-description'] agent=StructuredChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nsearch: search(query: str) -> str - 只有需要了解实时信息或不知道的事情的时候才会使用这个工具., args: {{\\'query\\': {{\\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or search\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EEF13A40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EEF11700>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')), output_parser=StructuredChatOutputParserWithRetries(output_fixing_parser=OutputFixingParser(parser=StructuredChatOutputParser(), retry_chain=LLMChain(prompt=PromptTemplate(input_variables=['completion', 'error', 'instructions'], template='Instructions:\\n--------------\\n{instructions}\\n--------------\\nCompletion:\\n--------------\\n{completion}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\n{error}\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000187EEF13A40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000187EEF11700>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://ai-yyds.com/v1', openai_proxy='https://ai-yyds.com/v1')))), allowed_tools=['search']) tools=[StructuredTool(name='search', description='search(query: str) -> str - 只有需要了解实时信息或不知道的事情的时候才会使用这个工具.', args_schema=<class 'pydantic.main.searchSchema'>, func=<function search at 0x00000187EF70CA40>)] handle_parsing_errors=True\n",
      "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "search: search(query: str) -> str - 只有需要了解实时信息或不知道的事情的时候才会使用这个工具., args: {{'query': {{'title': 'Query', 'type': 'string'}}}}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or search\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
      "Thought:\n",
      "{input}\n",
      "\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import  ChatOpenAI\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    "    tool\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"只有需要了解实时信息或不知道的事情的时候才会使用这个工具.\"\"\"\n",
    "    serp = SerpAPIWrapper()\n",
    "    return serp.run(query)\n",
    "    \n",
    "agent = initialize_agent(\n",
    "    [search],\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=memory,#记忆组件\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(agent)\n",
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)\n",
    "print(agent.agent.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Langchain is not a widely-known term or entity that would fall into common knowledge as of my last update, and it could refer to a specific product, project, or concept that has arisen after my last update. To provide accurate information, I would need to conduct a search.\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"search\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"What is langchain?\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\"LangChain is a framework designed to simplify the creation of applications using large language models. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\", 'LangChain entity_type: kp3_verticals.', 'LangChain kgmid: /g/11kjpl7_60.', 'LangChain initial_release_date: October 2022.', 'LangChain developer_s: Harrison Chase.', 'LangChain license: MIT License.', 'LangChain repository: github.com/langchain-ai/langchain.', 'LangChain stable_release: 0.1.16 / 11 April 2024; 5 months ago.', 'LangChain written_in: Python and JavaScript.', 'LangChain is a framework to build with LLMs by chaining interoperable components. LangGraph is the framework for building controllable agentic workflows.', 'LangChain provides AI developers with tools to connect language models with external data sources. It is open-source and supported by an active community.', 'LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models.', 'LangChain is a framework that simplifies the process of creating generative AI application interfaces. Developers working on these types of interfaces use ...', 'LangChain is a framework for developing applications powered by large language models (LLMs). LangChain simplifies every stage of the LLM application lifecycle.', 'LangChain is a framework for developing applications powered by large language models (LLMs). For these applications, LangChain simplifies the entire ...', 'Langchain makes creating agents using large language models simple through their agents API. Developers can use OpenAI functions or other means ...', 'LangChain is a Python framework designed to streamline AI application development, focusing on real-time data processing and integration ...', 'LangChain is a framework that allows developers to create agents capable of reasoning about issues and breaking them down into smaller sub-tasks ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results provide a comprehensive overview of what Langchain is, including its purpose, initial release date, developer, license, repository, stable release, programming languages it's written in, and its general use-cases. It is described as a framework designed to simplify the creation of applications using large language models, with a focus on chaining interoperable components and building controllable agentic workflows. It is open-source, written in Python and JavaScript, and provides tools for connecting language models with external data sources. It also mentions a component called LangGraph, which is used for building workflows.\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Langchain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It was initially released in October 2022 and is developed by Harrison Chase. Langchain is written in Python and JavaScript, and its stable release as of April 2024 is version 0.1.16. The framework provides tools for developers to connect language models with external data sources and is supported by an active community. It is particularly focused on chaining interoperable components and building controllable agentic workflows through a component called LangGraph. The framework is available on GitHub and is licensed under the MIT License.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langchain?',\n",
       " 'chat_history': [HumanMessage(content='what is langchain?'),\n",
       "  AIMessage(content='Langchain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It was initially released in October 2022 and is developed by Harrison Chase. Langchain is written in Python and JavaScript, and its stable release as of April 2024 is version 0.1.16. The framework provides tools for developers to connect language models with external data sources and is supported by an active community. It is particularly focused on chaining interoperable components and building controllable agentic workflows through a component called LangGraph. The framework is available on GitHub and is licensed under the MIT License.')],\n",
       " 'output': 'Langchain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It was initially released in October 2022 and is developed by Harrison Chase. Langchain is written in Python and JavaScript, and its stable release as of April 2024 is version 0.1.16. The framework provides tools for developers to connect language models with external data sources and is supported by an active community. It is particularly focused on chaining interoperable components and building controllable agentic workflows through a component called LangGraph. The framework is available on GitHub and is licensed under the MIT License.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\":\"what is langchain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加的具体几种agent\n",
    "### Several different types of agent\n",
    "- https://python.langchain.com/v0.1/docs/modules/agents/agent_types/\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
